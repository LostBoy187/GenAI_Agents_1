{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis Simple Agent\n",
    "\n",
    "## Overview\n",
    "This tutorial guides you through creating an AI-powered data analysis agent that can interpret and answer questions about a dataset using natural language. It combines language models with data manipulation tools to enable intuitive data exploration.\n",
    "\n",
    "## Motivation\n",
    "Data analysis often requires specialized knowledge, limiting access to insights for non-technical users. By creating an AI agent that understands natural language queries, we can democratize data analysis, allowing anyone to extract valuable information from complex datasets without needing to know programming or statistical tools.\n",
    "\n",
    "## Key Components\n",
    "1. Language Model: Processes natural language queries and generates human-like responses\n",
    "2. Data Manipulation Framework: Handles dataset operations and analysis\n",
    "3. Agent Framework: Connects the language model with data manipulation tools\n",
    "4. Synthetic Dataset: Represents real-world data for demonstration purposes\n",
    "\n",
    "## Method\n",
    "1. Create a synthetic dataset representing car sales data\n",
    "2. Construct an agent that combines the language model with data analysis capabilities\n",
    "3. Implement a query processing function to handle natural language questions\n",
    "4. Demonstrate the agent's abilities with example queries\n",
    "\n",
    "## Conclusion\n",
    "This approach to data analysis offers significant benefits:\n",
    "- Accessibility for non-technical users\n",
    "- Flexibility in handling various query types\n",
    "- Efficient ad-hoc data exploration\n",
    "\n",
    "By making data insights more accessible, this method has the potential to transform how organizations leverage their data for decision-making across various fields and industries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and set environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_experimental in c:\\users\\keeno\\anaconda3\\lib\\site-packages (0.3.4)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.28 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from langchain_experimental) (0.3.68)\n",
      "Requirement already satisfied: langchain-community<0.4.0,>=0.3.0 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from langchain_experimental) (0.3.27)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.4.4)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.6.7)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.3.26)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.4.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.12.13)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.10.1)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.28.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (9.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.4.39)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (6.0)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.28->langchain_experimental) (24.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.28->langchain_experimental) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.28->langchain_experimental) (4.13.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.28->langchain_experimental) (2.11.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.6.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.20.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (4.0.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.7.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.26.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.28->langchain_experimental) (2.1)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from langchain<1.0.0,>=0.3.26->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.3.8)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.23.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.28.1)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.10.16)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.28->langchain_experimental) (2.33.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.28->langchain_experimental) (0.4.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.28->langchain_experimental) (0.7.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.1.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2025.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.0.1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.7)\n",
      "Requirement already satisfied: anyio in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.5.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.14.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.4.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\keeno\\anaconda3\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "!pip install langchain_experimental\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain_openai import ChatOpenAI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables and set OpenAI API key\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q kaggle kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading API Key and configuring the language model...\n",
      "Language model initialized with: gpt-4.1-nano\n",
      "\n",
      "Downloading and loading the Kaggle dataset...\n",
      "Dataset URL: https://www.kaggle.com/datasets/shivamb/netflix-shows\n",
      "'netflix_titles.csv' successfully loaded into a DataFrame.\n",
      "\n",
      "First 5 rows of the Netflix data:\n",
      "  show_id     type                  title         director  \\\n",
      "0      s1    Movie   Dick Johnson Is Dead  Kirsten Johnson   \n",
      "1      s2  TV Show          Blood & Water              NaN   \n",
      "2      s3  TV Show              Ganglands  Julien Leclercq   \n",
      "3      s4  TV Show  Jailbirds New Orleans              NaN   \n",
      "4      s5  TV Show           Kota Factory              NaN   \n",
      "\n",
      "                                                cast        country  \\\n",
      "0                                                NaN  United States   \n",
      "1  Ama Qamata, Khosi Ngema, Gail Mabalane, Thaban...   South Africa   \n",
      "2  Sami Bouajila, Tracy Gotoas, Samuel Jouy, Nabi...            NaN   \n",
      "3                                                NaN            NaN   \n",
      "4  Mayur More, Jitendra Kumar, Ranjan Raj, Alam K...          India   \n",
      "\n",
      "           date_added  release_year rating   duration  \\\n",
      "0  September 25, 2021          2020  PG-13     90 min   \n",
      "1  September 24, 2021          2021  TV-MA  2 Seasons   \n",
      "2  September 24, 2021          2021  TV-MA   1 Season   \n",
      "3  September 24, 2021          2021  TV-MA   1 Season   \n",
      "4  September 24, 2021          2021  TV-MA  2 Seasons   \n",
      "\n",
      "                                           listed_in  \\\n",
      "0                                      Documentaries   \n",
      "1    International TV Shows, TV Dramas, TV Mysteries   \n",
      "2  Crime TV Shows, International TV Shows, TV Act...   \n",
      "3                             Docuseries, Reality TV   \n",
      "4  International TV Shows, Romantic TV Shows, TV ...   \n",
      "\n",
      "                                         description  \n",
      "0  As her father nears the end of his life, filmm...  \n",
      "1  After crossing paths at a party, a Cape Town t...  \n",
      "2  To protect his family from a powerful drug lor...  \n",
      "3  Feuds, flirtations and toilet talk go down amo...  \n",
      "4  In a city of coaching centers known to train I...  \n",
      "\n",
      "Creating the data analysis agent...\n",
      "\n",
      "----------------------------------------------------\n",
      "✅ Setup complete! The AI agent is ready to use.\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# FINAL WORKING SCRIPT FOR THE DATA ANALYSIS AGENT\n",
    "# ===================================================================\n",
    "\n",
    "# PART 1: IMPORTS AND SETUP\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# LangChain and AI components\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "# Kaggle API for downloading the dataset\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "# .env file for the API key\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# PART 2: LOAD API KEY AND CONFIGURE THE LANGUAGE MODEL\n",
    "print(\"Loading API Key and configuring the language model...\")\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"API Key not found. Please check your .env file.\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "\n",
    "# Configure the language model to use the cost-effective gpt-4.1-nano\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4.1-nano\",\n",
    "    temperature=0\n",
    ")\n",
    "print(f\"Language model initialized with: {llm.model_name}\")\n",
    "\n",
    "\n",
    "# PART 3: DOWNLOAD AND LOAD THE DATASET\n",
    "print(\"\\nDownloading and loading the Kaggle dataset...\")\n",
    "# Authenticate and download the dataset using the direct Kaggle API\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "api.dataset_download_files('shivamb/netflix-shows', path='.', unzip=True)\n",
    "\n",
    "# Load the downloaded CSV file into a pandas DataFrame\n",
    "dataset_name = \"netflix_titles.csv\"\n",
    "df = pd.read_csv(dataset_name)\n",
    "print(f\"'{dataset_name}' successfully loaded into a DataFrame.\")\n",
    "\n",
    "# Display a sample of the data to confirm it's correct\n",
    "print(\"\\nFirst 5 rows of the Netflix data:\")\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# PART 4: CREATE THE DATA ANALYSIS AGENT\n",
    "print(\"\\nCreating the data analysis agent...\")\n",
    "# Create the agent, passing in the language model, the dataframe, and allowing code execution\n",
    "agent = create_pandas_dataframe_agent(\n",
    "    llm=llm,\n",
    "    df=df,\n",
    "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    allow_dangerous_code=True  # Opt-in to the security feature\n",
    ")\n",
    "\n",
    "print(\"\\n----------------------------------------------------\")\n",
    "print(\"✅ Setup complete! The AI agent is ready to use.\")\n",
    "print(\"----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to identify the column headers in the dataframe `df`. I can do this by examining `df.columns`.\n",
      "\n",
      "Action: python_repl_ast\n",
      "Action Input: df.columns.tolist()\u001b[0m\u001b[36;1m\u001b[1;3m['show_id', 'type', 'title', 'director', 'cast', 'country', 'date_added', 'release_year', 'rating', 'duration', 'listed_in', 'description']\u001b[0m\u001b[32;1m\u001b[1;3mFinal Answer: The column headers in the dataset are 'show_id', 'type', 'title', 'director', 'cast', 'country', 'date_added', 'release_year', 'rating', 'duration', 'listed_in', and 'description'.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The column headers in the dataset are 'show_id', 'type', 'title', 'director', 'cast', 'country', 'date_added', 'release_year', 'rating', 'duration', 'listed_in', and 'description'.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In a new cell, run this:\n",
    "agent.run(\"what are the column headers in the dataset?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Questions\n",
    "\n",
    "Here are some example questions you can ask the data analysis agent. You can modify these or add your own questions to analyze the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to retrieve the column names from the dataframe `df`.  \n",
      "Action: python_repl_ast  \n",
      "Action Input: df.columns.tolist()  \u001b[0m\u001b[36;1m\u001b[1;3m['show_id', 'type', 'title', 'director', 'cast', 'country', 'date_added', 'release_year', 'rating', 'duration', 'listed_in', 'description']\u001b[0m\u001b[32;1m\u001b[1;3mFinal Answer: The column names in the dataset are 'show_id', 'type', 'title', 'director', 'cast', 'country', 'date_added', 'release_year', 'rating', 'duration', 'listed_in', and 'description'.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To determine the number of rows in the dataset, I need to check the shape of the dataframe `df`. The number of rows is given by the first element of the shape tuple.\n",
      "\n",
      "Action: python_repl_ast\n",
      "\n",
      "Action Input: df.shape[0]\u001b[0m\u001b[36;1m\u001b[1;3m8807\u001b[0m\u001b[32;1m\u001b[1;3mFinal Answer: The dataset contains 8,807 rows.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The dataset contains 8,807 rows.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example questions\n",
    "agent.run(\"What are the column names in this dataset?\")\n",
    "agent.run(\"How many rows are in this dataset?\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
